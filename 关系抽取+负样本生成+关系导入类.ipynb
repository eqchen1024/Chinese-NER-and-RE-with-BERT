{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import random\n",
    "class relations:\n",
    "    def __init__(self):\n",
    "        self.tag_dic = {\"has_clinical_manifestation\":\"临床表现\",\n",
    "           \"cause\":\"病因\",\n",
    "           \"diagnose\":\"诊断\",\n",
    "           \"medical_treat\":\"治疗\",\n",
    "           \"prevent\":\"预防\",\n",
    "           \"is_synonym\":\"同义\",\n",
    "           'is_synonym_drug':\"同义\",\n",
    "           'is_synonym_mechanism':\"同义\",\n",
    "           'is_synonym_cause':\"同义\",\n",
    "           'is_synonym_surgery': \"同义\",\n",
    "           'is_synonym_symptom':\"同义\",\n",
    "           'is_synonym_prevention':\"同义\",\n",
    "           'is_synonym_inspection':\"同义\",\n",
    "           'is_synonym_technology':\"同义\",\n",
    "           'is_synonym_therapy':\"同义\",\n",
    "           'is_synonym_nursing':\"同义\",\n",
    "           'is_synonym_indicator':\"同义\",\n",
    "           \"is_pathology\":\"病理\",\n",
    "           \"nurse\":\"护理\",\n",
    "           \"report\":\"报告\",\n",
    "           \"inspect\":\"观察\",\n",
    "           \"non-medication_treat\":\"治疗\",\n",
    "           \"surgical_treat\":\"治疗\",\n",
    "           \"disease\": \"疾病\",\n",
    "           \"drug\": \"药物\",\n",
    "           \"surgery\": \"手术\",\n",
    "           \"symptom\": \"症状\",\n",
    "           \"prevention\": \"预防措施\",\n",
    "           \"inspection_method\": \"观察方法\",\n",
    "           \"diagnostic_technology\": \"诊断技术\",\n",
    "           \"non-drug_therapy\": \"非药疗法\",\n",
    "           \"nursing_technology\": \"护理技术\",\n",
    "           \"cause_of_disease\": \"病因\",\n",
    "           \"pathological_mechanism\": \"病理\",\n",
    "           'medical_indicator': '医疗指标',\n",
    "           'has_subclass':'分为',\n",
    "           'has_indicator':'检测项目为',\n",
    "           'has_inspector':'检测项目为',\n",
    "           'drug_effect':'作用于',\n",
    "           'drug_effect_symptom':'作用于',\n",
    "           'drug_effect_pathological':'作用于',\n",
    "           'non-drug_therapy_effect':'作用于',\n",
    "           'prevention_effect':'作用于',\n",
    "           'drug_cause_of_disease':'作用于',\n",
    "           'lead':\"导致\",\n",
    "           'diagnostic_pathological':'诊断',\n",
    "           'indicate_symptom':\"揭示\",\n",
    "           'nursing_symptom':'护理',\n",
    "            'is_complication':'并发症'\n",
    "           \n",
    "          }\n",
    "    def get_relation(self,ann_file):\n",
    "        with codecs.open(ann_file, \"r\", encoding=\"utf-8\") as f:#读取标签文件\n",
    "            line = f.readline()#获取第一行\n",
    "            print(line)\n",
    "            line = line.strip(\"\\n\\r\")\n",
    "            entity=[]#标注文件中的实体储存在此处\n",
    "            relation=[]#标注文件中的关系储存在此处\n",
    "            while line != \"\":\n",
    "                line_arr = line.split()\n",
    "                cls = self.tag_dic[line_arr[1]] #转换为中文标签\n",
    "                line_arr[1]=cls#中文标签替换\n",
    "                if \"T\" in line_arr[0]:\n",
    "                    entity.append(line_arr)#实体存入entity\n",
    "                else:\n",
    "                    relation.append(line_arr)#关系存入relation\n",
    "                print(line_arr)\n",
    "                line = f.readline()#读取下一个\n",
    "                line = line.strip(\"\\n\\r\")\n",
    "            for i in range(len(relation)):\n",
    "                for j in range(len(entity)):\n",
    "                    if entity[j][0]==relation[i][2][5:]:\n",
    "                        relation[i][2]=entity[j][2:]\n",
    "                    if entity[j][0]==relation[i][3][5:]:\n",
    "                        relation[i][3]=entity[j][2:]\n",
    "        return relation,entity\n",
    "    def sentence_trans(self,txt):\n",
    "        with codecs.open(txt, \"r\", encoding=\"utf-8\") as f:#读取文本文档\n",
    "            content_str = f.read()\n",
    "            con=content_str.replace(\"\\r\\n\",\"。。\")\n",
    "        return con\n",
    "    def clean_sen(self,con):\n",
    "        p1 = r\"。+\"\n",
    "        pattern1 = re.compile(p1)\n",
    "        print(pattern1.findall(con))\n",
    "        newKey = re.sub(p1, \"。\", con)\n",
    "        sen_full=newKey.split(\"。\")\n",
    "        cleaned_sen=[]\n",
    "        for i in sen_full:\n",
    "            i=i.replace(\"(\",'')\n",
    "            i=i.replace(\")\",'')\n",
    "            i=i.replace(\" \",'')\n",
    "            i=i.replace(\"Alzheimer's\",\"Alzheimer'sdisease\")\n",
    "            cleaned_sen.append(i)\n",
    "        return cleaned_sen\n",
    "    def mark_pos(self,con):\n",
    "        full_mark_list=[]\n",
    "        for i,full_mark in enumerate(con):\n",
    "            if (full_mark==\"。\") :\n",
    "                full_mark_list.append(i)\n",
    "        del_li=[]\n",
    "        for i in range(len(full_mark_list)):\n",
    "            try:\n",
    "                if full_mark_list[i+1]-full_mark_list[i]==1:\n",
    "                    del_li.append(full_mark_list[i+1])\n",
    "            except:\n",
    "                pass\n",
    "        cleaned_li=[]\n",
    "        for i in full_mark_list:\n",
    "            if i not in del_li:\n",
    "                cleaned_li.append(i)\n",
    "        return cleaned_li\n",
    "    def get_triple(self,con,relation):\n",
    "        cleaned_li=self.mark_pos(con)\n",
    "        cleaned_sen=self.clean_sen(con)\n",
    "        relation_sen=[]\n",
    "        for i in relation:\n",
    "            i[2][2]=i[2][2].replace(\"(\",'')\n",
    "            i[2][2]=i[2][2].replace(\"(\",'')\n",
    "            i[2][2]=i[2][2].replace(\" \",'')\n",
    "            i[2][2]=i[2][2].replace(\"Alzheimer's\",\"Alzheimer'sdisease\")\n",
    "            i[3][2]=i[3][2].replace(\")\",'')\n",
    "            i[3][2]=i[3][2].replace(\")\",'')\n",
    "            i[3][2]=i[3][2].replace(\" \",'')\n",
    "            i[3][2]=i[3][2].replace(\"Alzheimer's\",\"Alzheimer'sdisease\")\n",
    "            try:\n",
    "                for j in range(len(cleaned_li)):\n",
    "                        if int(i[2][0])>int(cleaned_li[j]) and int(i[2][0])<int(cleaned_li[j+1]) and int(i[3][0])>int(cleaned_li[j]) and int(i[3][0])<int(cleaned_li[j+1]):\n",
    "                            relation_sen.append([i[1],i[2][2],i[3][2],j,cleaned_sen[j+1]])#中间的句子也要放进去 我需要句子的index\n",
    "            except:\n",
    "                pass\n",
    "        return relation_sen\n",
    "    def run(self):\n",
    "        relation,entity=self.get_relation(r\".\\关系抽取\\abstract_000.ann\")\n",
    "        con=self.sentence_trans(r\".\\关系抽取\\abstract_000.txt\")\n",
    "        \n",
    "        \n",
    "        relation_sen=self.get_triple(con,cleaned_li,cleaned_sen,relation)\n",
    "        sample=self.neg_sample(cleaned_sen,cleaned_li,relation_sen,entity,relation,500)\n",
    "        w_path=\"./test.txt\"\n",
    "        with codecs.open(w_path, \"w\", encoding=\"utf-8\") as w:\n",
    "            for i in sample:\n",
    "                w.write(i[0]+\"\\t\"+i[1]+\"\\t\"+\"unknown\"+\"\\t\"+i[2])\n",
    "                w.write(\"\\r\\n\")\n",
    "    def neg_sample(self,cleaned_sen,cleaned_li,relation_sen,entity,relation,sample_size):\n",
    "    #制作负样本 找出句子中所有的实体\n",
    "        sen_for_unkn=[]\n",
    "        for i in range(len(cleaned_sen)):\n",
    "            sen_for_unkn.append([cleaned_sen[i]])\n",
    "        for i in entity:\n",
    "            for j in range(len(cleaned_li)):\n",
    "                if int(i[2])>int(cleaned_li[j]) and int(i[2])<int(cleaned_li[j+1]):\n",
    "                    sen_for_unkn[j+1].append(i[4])\n",
    "        relation_pair=[]\n",
    "        for i in relation_sen:\n",
    "            if [i[1],i[2]] not in relation_pair:\n",
    "                relation_pair.append([i[1],i[2]])\n",
    "        syn_word=[]\n",
    "        for i in relation:\n",
    "            if i[1]==\"同义\":\n",
    "                syn_word.append([i[2][2],i[3][2]])\n",
    "        relat_plus_syn=[]\n",
    "        for i in relation_pair:\n",
    "            for j in syn_word:\n",
    "                if i[0] ==j[0]:\n",
    "                    relat_plus_syn.append([j[1],i[1]])\n",
    "                if i[1] ==j[0]:\n",
    "                    relat_plus_syn.append([i[0],j[1]])\n",
    "                if i[0] ==j[1]:\n",
    "                    relat_plus_syn.append([j[0],i[1]])\n",
    "                if i[1] ==j[1]:\n",
    "                    relat_plus_syn.append([i[0],j[0]])\n",
    "        plused_reli=relation_pair+relat_plus_syn\n",
    "        unkn_li=[]\n",
    "        for i in sen_for_unkn:\n",
    "            for j in i[1:]:\n",
    "                for k in i[1:]:\n",
    "                    if j!=k and(([j,k]  not in plused_reli) and ([k,j] not in plused_reli)) and (j!=\"老年痴呆\" or j!='AD') and (k!=\"老年痴呆\" or k!='AD'):\n",
    "                        unkn_li.append([j,k,i[0]])\n",
    "        sample=random.sample(unkn_li, sample_size)\n",
    "        return sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
